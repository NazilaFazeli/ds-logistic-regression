{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "center-compilation",
   "metadata": {},
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-throat",
   "metadata": {},
   "source": [
    "In this notebook we will use the flower iris dataset which is often called the \"Hello world!\" of Machine Learning.\n",
    "\n",
    "Our aim is to train a model which predicts the iris species, e.g, setosa, versicolor', virginica based on its petal and sepal measures. In our case we are not dealing with a binary classification problem but with a multiclass classification problem. Our model should be able to predict one of the three iris species. \n",
    "\n",
    "Writing the code for training a multiclass logistic regression model works exactly as when dealing with a binary problem. If you are interested in how logistic regression handles multiclass problems have a look at the sklearn [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "\n",
    "After got the data and defined our features and the target variable, we will split the dataset into 70% trainings data and 30% testing data. Then, \n",
    "1. we make a short EDA on the train data\n",
    "2. we will train (fit) our logistic regression model on the training data and evaluate the performance on the remaining 30%. \n",
    "\n",
    "\n",
    "At this point of the course the structure of the notebook should be familiar to you. At the end you should:\n",
    "* know one of the most popular data sets in machine learning ;) \n",
    "* know how to apply logistic regression to a multiclass problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-swaziland",
   "metadata": {},
   "source": [
    "## Setup and Data\n",
    "\n",
    "We will begin with importing the required libraries and data. This time we will import the dataset directly from sklearn. Sklearn provide some of the most commonly used [toy data sets](https://scikit-learn.org/stable/datasets/toy_dataset.html) for learning and practicing machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['figure.figsize'] = (11, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf28ef-b391-4b22-aef4-930a7cfd7279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import data from sklearn.datasets\n",
    "data = load_iris()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8178f27-9611-4abf-b92d-3d594a33b1b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d41b52d-ee1e-4d63-985c-10ec495706c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = data.data\n",
    "y = data.target\n",
    "target_names = data.target_names\n",
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d95f8d-c1ae-48c9-8f6c-9f301fbbe6fe",
   "metadata": {},
   "source": [
    "## Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0deb97d-66c7-4ba4-8bd8-900bfb228cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=15, shuffle=True, stratify=y)\n",
    "\n",
    "# Check the shape of the data sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b46576f-1b6e-4d40-9284-1655e639fbe4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942b86b-0000-45ef-85c2-7ddbec59595d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check data type\n",
    "print(\"X_train data type:\", type(X_train))\n",
    "print(\"y_train data type:\", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37949724-a081-4ebc-a4ed-f4e6cf180fcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert X_train to dataframe\n",
    "df_X_train = pd.DataFrame(data=X_train, columns=data.feature_names)\n",
    "df_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d86de7f-183a-4612-a7ec-807bd4f92ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert y_train to dataframe\n",
    "df_y_train = pd.DataFrame(data=y_train, columns=['species'])\n",
    "df_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e8c06-341c-4ef4-880d-0f1a18f552ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine df_X_train and df_y_train into df_train\n",
    "df_train = pd.concat([df_X_train,df_y_train], axis=1,ignore_index=False)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f67b04-897b-494b-8a8c-3ecb84393972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 0 with setosa, 1 with versicolar and 2 with virginica in the columns species\n",
    "df_train.species.replace({0: target_names[0], 1: target_names[1], 2: target_names[2]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check result\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-financing",
   "metadata": {},
   "source": [
    "### Getting a feel for the data\n",
    "\n",
    "Before we dive into the modelling part we will examine the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the columns and data types \n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics \n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for number of unique values\n",
    "df_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c60060-537c-41a3-802a-ab23b825e6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's check wether the target variable is balanced\n",
    "df_train['species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-norfolk",
   "metadata": {
    "tags": []
   },
   "source": [
    "The information above look promising: \n",
    "* We have four features which seem to be all numerical ones.\n",
    "* Our target variable *species* is categorical and is balanced\n",
    "* None of our columns has missing data. \n",
    "* Based on the table with the descriptive statistics we can assume that there are no strong outliers. \n",
    "\n",
    "It's always a good idea to visualize the data to get more insight and to confirm our first assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-while",
   "metadata": {},
   "source": [
    "### Visualisation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-christian",
   "metadata": {},
   "source": [
    "We will start by plotting the target variable. We can see that our dataset is very balanced with 50 specimens of each species. That's good, so we won't have to deal with an imbalanced data set when it comes to the modelling part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the target variable\n",
    "plt.title('Species Count')\n",
    "sns.countplot(x=df_train.species);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-algorithm",
   "metadata": {},
   "source": [
    "A pair plot is good to see all the column relationships at once. It's perfect to get an overview of the data but not really useful when it comes to presenting our work to someone else.\n",
    "\n",
    "We can see from the pair plot that the three species can be pretty well separated. There seems to be only minor overlaps between the species versicolor and virginica. This is good and will hopefully result in a good performance of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_train, hue=\"species\", height=3,corner=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-waters",
   "metadata": {},
   "source": [
    "To confirm our first impression from the pairplot we can pick some of the feature combinations and visualize them again with bigger plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Comparison between sepal width and length on the basis of species')\n",
    "sns.scatterplot(x=df_train['sepal length (cm)'], y=df_train['sepal width (cm)'], hue = df_train['species'], s= 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Comparison between petal width and length on the basis of species')\n",
    "sns.scatterplot(x=df_train['petal length (cm)'], y=df_train['petal width (cm)'], hue = df_train['species'], s= 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-layer",
   "metadata": {},
   "source": [
    "It is clearly visible that the species iris setosa is separable from the other two species, while there is some overlapping regarding iris versicolor and iris virginica.\n",
    "\n",
    "It's always worth to have a look at the correlations of our numerical features. \n",
    "From the heatmap we can see that petal length and petal width are strongly correlated. Sepal length shows also a strong correlation to petal length and petal width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02bfb2a-18e2-4128-bfb9-baa0bdac0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap \n",
    "correlations = df_train.corr(numeric_only=True)\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5319a1-b619-44ae-a352-26cc017147e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(correlations)\n",
    "sns.heatmap(correlations , vmax=1, vmin=-1, annot=True, mask=mask, cmap=\"YlGnBu\",);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdadfa9-6848-415b-a640-f263b2efa9f3",
   "metadata": {},
   "source": [
    "## Featuring Engineering\n",
    "\n",
    "Not done yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-montreal",
   "metadata": {},
   "source": [
    "## Train Model(s)\n",
    "Since our dataset is completely balanced we decide that accuracy is a good metric to evaluate the performance of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0802892b-a427-4daa-9d93-5a43f9ea6403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f615cf0-a1e1-49c2-a467-ee2df9331344",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02ed665-8b80-424c-89b5-8b82ebdf9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_train = log_reg.predict(X_train)\n",
    "y_pred_test = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0459df2-83f2-4af0-bf00-0a5697630f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy of our model\n",
    "print(\"Accuracy on train set:\", round(accuracy_score(y_train, y_pred_train), 2))\n",
    "print(\"Accuracy on test set:\", round(accuracy_score(y_test, y_pred_test), 2))\n",
    "print(\"--------\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967733f-3fe2-4c6e-971a-de88e5cc518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report of our model\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"--------\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f7db0c-911b-414a-98bb-95d4166970be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model with a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ec7b6-6dc9-482b-bdd4-b5e48b83fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(cm, cmap='YlGnBu', \n",
    "            annot=True, fmt='d', \n",
    "            linewidths=.5, xticklabels=data.target_names, \n",
    "            yticklabels=data.target_names, ax=ax)\n",
    "fig.supxlabel(\"predicted\")\n",
    "fig.supylabel(\"actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-franchise",
   "metadata": {},
   "source": [
    "Our model is working pretty well. We reached an accuracy of 0.98 on the train set and 0.93 on our test set. That's really good. \n",
    "If we have a look at the confusion matrix we can see that our model perfectly classified all instances of iris setosa really as iris setosa. \n",
    "When it comes to the observations for versicolar and virginica species, the model gets a bit confused:\n",
    "+ 1 out of the 15 versicolar observation gets misclassified as virginica, and the remaining 14 are correctly classified\n",
    "+ 2 out of the 15 virginica observation gets misclassified as versicolar, and the remaining 13 are correctly classified\n",
    "\n",
    "If we recall our observations from the EDA regarding the separability of the three species this is not a big surprise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe23ca-a09c-448f-92b2-853541a136b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
